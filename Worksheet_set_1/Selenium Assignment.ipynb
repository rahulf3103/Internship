{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a20e2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing of lib.\n",
    "## pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "089b2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Lib\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e599ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the Browser\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858b071f",
   "metadata": {},
   "source": [
    "## Ques. 1\n",
    "Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a819510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a0dd6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job = driver.find_element_by_class_name(\"suggestor-input \")#extracting element\n",
    "search_job.send_keys(\"Data Analyst\")#Entering data in search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e4d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_locn = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')#extracting element\n",
    "search_locn.send_keys(\"Bangalore\")#Entering data in search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0799b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')#extracting element\n",
    "search_btn.click()#Clicking on the seach bbutton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd7c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "title_tags = [] #empty list\n",
    "location = []\n",
    "company = []\n",
    "exper = []\n",
    "\n",
    "tit = driver.find_elements_by_xpath('//a[@class = \"title fw500 ellipsis\"]')\n",
    "title = tit[0:10]    #fixing the boundries(how much data we want to extract)\n",
    "loc = driver.find_elements_by_xpath('//li[@class = \"fleft grey-text br2 placeHolderLi location\"]')\n",
    "locc = loc[0:10]    \n",
    "com = driver.find_elements_by_xpath('//a[@class = \"subTitle ellipsis fleft\"]')\n",
    "comp = com[0:10]    \n",
    "exp = driver.find_elements_by_xpath('//li[@class = \"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "expp = exp[0:10]   \n",
    "\n",
    "for i in title:\n",
    "    title_tags.append(i.text) #appending the text in Title_tags list\n",
    "print(len(title_tags))\n",
    "for j in locc:\n",
    "    location.append(j.text) #Fetching text data\n",
    "print(len(location))\n",
    "for k in comp:\n",
    "    company.append(k.text)\n",
    "print(len(company))\n",
    "for l in expp:\n",
    "    exper.append(l.text)\n",
    "print(len(exper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "796a1389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring Data Analyst For Global Logic-Immediate...</td>\n",
       "      <td>Noida, Nagpur, Pune, Gurgaon/Gurugram, Bangalo...</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Junior Data Analyst/ Scientist- Fresher Position</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "      <td>Sejal Consulting Hub</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assistant Clinical Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Labcorp Drug Development India Private Limited</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead - Data Analyst / Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Axim Technologies</td>\n",
       "      <td>12-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst / Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Vmware</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst - CRM</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek Tech</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst - Supporting Audits</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Visa</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Research - Data Analyst / Associate</td>\n",
       "      <td>Mumbai, Delhi / NCR, Bangalore/Bengaluru</td>\n",
       "      <td>AXL HR Tech</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SAM Data Analyst</td>\n",
       "      <td>Noida, Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Hiring Data Analyst For Global Logic-Immediate...   \n",
       "1                                Senior Data Analyst   \n",
       "2   Junior Data Analyst/ Scientist- Fresher Position   \n",
       "3                    Assistant Clinical Data Analyst   \n",
       "4                    Lead - Data Analyst / Scientist   \n",
       "5                    Data Analyst / Sr. Data Analyst   \n",
       "6                          Senior Data Analyst - CRM   \n",
       "7            Senior Data Analyst - Supporting Audits   \n",
       "8                Research - Data Analyst / Associate   \n",
       "9                                   SAM Data Analyst   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Noida, Nagpur, Pune, Gurgaon/Gurugram, Bangalo...   \n",
       "1                                Bengaluru/Bangalore   \n",
       "2  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8           Mumbai, Delhi / NCR, Bangalore/Bengaluru   \n",
       "9                 Noida, Mumbai, Bangalore/Bengaluru   \n",
       "\n",
       "                                     Company Name Experience Required  \n",
       "0                                     GlobalLogic             4-8 Yrs  \n",
       "1                                        Flipkart             4-6 Yrs  \n",
       "2                            Sejal Consulting Hub             0-3 Yrs  \n",
       "3  Labcorp Drug Development India Private Limited             0-2 Yrs  \n",
       "4                               Axim Technologies           12-14 Yrs  \n",
       "5                                          Vmware             3-6 Yrs  \n",
       "6                                      Gojek Tech             2-5 Yrs  \n",
       "7                                            Visa             5-8 Yrs  \n",
       "8                                     AXL HR Tech             0-2 Yrs  \n",
       "9                                           Nokia             1-2 Yrs  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame() #Creating dataframe\n",
    "df['Job Title'] = title_tags\n",
    "df['Job Location'] = location\n",
    "df['Company Name'] = company\n",
    "df['Experience Required'] = exper\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5581cf07",
   "metadata": {},
   "source": [
    "## Ques. 2\n",
    "Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f61a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url1 = 'https://www.naukri.com/'\n",
    "driver.get(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f2ab8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job1 = driver.find_element_by_class_name(\"suggestor-input \")#extracting element\n",
    "search_job1.send_keys(\"Data Scientist\") #Entering data in search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37f7f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_locn1 = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "search_locn1.send_keys(\"Bangalore\")#Entering data in search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0cc1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn1 = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5d3932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "title_tags1 = []\n",
    "location1 = []\n",
    "company1 = []\n",
    "\n",
    "title_tag1 = driver.find_elements_by_xpath('//a[@class = \"title fw500 ellipsis\"]')\n",
    "title1=title_tag1[0:10] #fixing the boundries(how much data we want to extract)\n",
    "loc1 = driver.find_elements_by_xpath('//li[@class = \"fleft grey-text br2 placeHolderLi location\"]')\n",
    "locc1 = loc1[0:10]\n",
    "com1 = driver.find_elements_by_xpath('//a[@class = \"subTitle ellipsis fleft\"]')\n",
    "comp1 = com1[0:10]\n",
    "\n",
    "for i in title1:\n",
    "    title_tags1.append(i.text)#appending the text in Title_tags list\n",
    "for j in locc1:\n",
    "    location1.append(j.text) #Fetching location data\n",
    "for k in comp1:\n",
    "    company1.append(k.text) \n",
    "    \n",
    "print(len(title_tags1)) #priting title_tags1\n",
    "print(len(location1))\n",
    "print(len(company1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50a085bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr . Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Harman Connected Services Corporation India Pvt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Slice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist - Python/Machine Learnin...</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Bangalor...</td>\n",
       "      <td>Altimax Business Solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior/Lead Data Scientist - (Revenue Management)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>o9 Solutions Management India Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior/Lead - Data Scientist (Supply Chain)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>o9 Solutions Management India Private Limited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                 Data Scientist: Advanced Analytics   \n",
       "1                 Data Scientist: Advanced Analytics   \n",
       "2                                Sr . Data Scientist   \n",
       "3                              Senior Data Scientist   \n",
       "4                                  Sr Data Scientist   \n",
       "5                              Senior Data Scientist   \n",
       "6                              Senior Data Scientist   \n",
       "7  Senior Data Scientist - Python/Machine Learnin...   \n",
       "8  Senior/Lead Data Scientist - (Revenue Management)   \n",
       "9        Senior/Lead - Data Scientist (Supply Chain)   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bengaluru/Bangalore   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Mumbai, Hyderabad/Secunderabad, Pune, Bangalor...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                       Company Name  \n",
       "0                                               IBM  \n",
       "1                                               IBM  \n",
       "2  Harman Connected Services Corporation India Pvt.  \n",
       "3                                             Slice  \n",
       "4                                           Siemens  \n",
       "5                                              Dell  \n",
       "6                                              Dell  \n",
       "7                        Altimax Business Solutions  \n",
       "8     o9 Solutions Management India Private Limited  \n",
       "9     o9 Solutions Management India Private Limited  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['Job Title'] = title_tags1\n",
    "df1['Job Location'] = location1\n",
    "df1['Company Name'] = company1\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69fa765",
   "metadata": {},
   "source": [
    "##  Ques 3 \n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50a2d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url2 = 'https://www.naukri.com/'\n",
    "driver.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4199558",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job2 = driver.find_element_by_class_name(\"suggestor-input \") #extracting element\n",
    "search_job2.send_keys(\"Data Scientist\") #Entering data in search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0ef68d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn2 = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn2.click() #Clicking on the search Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deb4d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_check = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/i')\n",
    "location_check.click() # Used location check to select “Delhi/NCR” and then we are clicking on to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e09133fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_check = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i')\n",
    "salary_check.click() # Used salary check to select “3-6” lakhs and then we are clicking on to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d47db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "title_tags2 = []\n",
    "location2 = []\n",
    "company2 = []\n",
    "exper2 = []\n",
    "\n",
    "title_tag2= driver.find_elements_by_xpath('//a[@class = \"title fw500 ellipsis\"]')\n",
    "title2= title_tag2[0:10] #fixing the boundries(how much data we want to extract)\n",
    "loc2 = driver.find_elements_by_xpath('//li[@class = \"fleft grey-text br2 placeHolderLi location\"]')\n",
    "locc2 = loc2[0:10]\n",
    "com2 = driver.find_elements_by_xpath('//a[@class = \"subTitle ellipsis fleft\"]')\n",
    "comp2 = com2[0:10]\n",
    "exp2 = driver.find_elements_by_xpath('//li[@class = \"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "expp2 = exp2[0:10]\n",
    "\n",
    "for i in title2:\n",
    "    title_tags2.append(i.text) #appending the text in title_tags2 list\n",
    "for j in locc2:\n",
    "    location2.append(j.text) #Fetching location data\n",
    "for k in comp2:\n",
    "    company2.append(k.text)\n",
    "for l in expp2:\n",
    "    exper2.append(l.text)\n",
    "\n",
    "print(len(title_tags2))#priting title_tags2\n",
    "print(len(company2))\n",
    "print(len(location2))\n",
    "print(len(exper2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad758f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Senior DS/ Team Lead</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram(Cyber City +1)</td>\n",
       "      <td>NebulARC Technologies Private Limited</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job Opportunity || Data Scientist || HCL Techn...</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>HCL</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Data Analyst / Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>Careerera</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram(Uday Nagar)</td>\n",
       "      <td>Core Diagnostics Private Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist | Python | Machine Learning | D...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Schlesinger Group</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Openings For Jr/mid/Sr level data Scientists</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Pluto seven business solutions (p) limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>T &amp; A Solutions</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Urgent Hiring For Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Urgent Hiring For Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0              Data Scientist / Senior DS/ Team Lead   \n",
       "1  Job Opportunity || Data Scientist || HCL Techn...   \n",
       "2           Hiring For Data Analyst / Data Scientist   \n",
       "3                            Senior Data Scientist I   \n",
       "4                                     Data Scientist   \n",
       "5  Data Scientist | Python | Machine Learning | D...   \n",
       "6       Openings For Jr/mid/Sr level data Scientists   \n",
       "7                                     Data Scientist   \n",
       "8                   Urgent Hiring For Data Scientist   \n",
       "9                   Urgent Hiring For Data Scientist   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0            Mumbai, Gurgaon/Gurugram(Cyber City +1)   \n",
       "1                                        Delhi / NCR   \n",
       "2                             Noida(Sector-59 Noida)   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4                       Gurgaon/Gurugram(Uday Nagar)   \n",
       "5               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "6  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "7                                   Gurgaon/Gurugram   \n",
       "8              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "9              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "\n",
       "                                 Company Name Experience Required  \n",
       "0       NebulARC Technologies Private Limited             0-4 Yrs  \n",
       "1                                         HCL             2-6 Yrs  \n",
       "2                                   Careerera             2-5 Yrs  \n",
       "3                                   Delhivery             3-7 Yrs  \n",
       "4            Core Diagnostics Private Limited             2-7 Yrs  \n",
       "5                           Schlesinger Group             0-3 Yrs  \n",
       "6  Pluto seven business solutions (p) limited             2-6 Yrs  \n",
       "7                             T & A Solutions             2-6 Yrs  \n",
       "8     Mount Talent Consulting Private Limited             1-6 Yrs  \n",
       "9     Mount Talent Consulting Private Limited             1-6 Yrs  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2['Job Title'] = title_tags2\n",
    "df2['Job Location'] = location2\n",
    "df2['Company Name'] = company2\n",
    "df2['Experience Required'] = exper2\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2cc58e",
   "metadata": {},
   "source": [
    "##  Ques 4\n",
    "Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands andmore” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this pageyou can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom ofthe page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7032ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url3 = 'https://www.flipkart.com/'\n",
    "driver.get(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84b8ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_class_name(\"_3704LK\") #extracting element\n",
    "search.send_keys(\"Sun Glasses\") #Entering data in search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccfd4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_class_name('L0Z3Pu')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb2dd9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0 #start page\n",
    "end=3 #end page\n",
    "\n",
    "brand = []\n",
    "price = []\n",
    "des = []\n",
    "off = []\n",
    "\n",
    "for page in range(start,end): #for loop for scrapping 3 page\n",
    "    brands=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")#scraping brands name by class name\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    descp=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    dis=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    \n",
    "    for i in brands:\n",
    "        brand.append(i.text) #appending the text in Brand list\n",
    "    for j in prices:\n",
    "        price.append(j.text)\n",
    "    for k in descp:\n",
    "        des.append(k.text)\n",
    "    for l in dis:\n",
    "        off.append(l.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\") #Scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href')) #Getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fd7c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=brand[0:100]\n",
    "p=price[0:100]\n",
    "d=des[0:100]\n",
    "o=off[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be264dbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " List of Brands:- \n",
      " ['Singco India', 'Singco India', 'PIRASO', 'Fastrack', 'Elligator', 'SRPM', 'kingsunglasses', 'DEIXELS', 'SHAAH COLLECTIONS', 'PIRASO', 'New Specs', 'AISLIN', 'SUNBEE', 'PIRASO', 'ROYAL SON', 'LOUIS KOUROS', 'kingsunglasses', 'kingsunglasses', 'SHAAH COLLECTIONS', 'AISLIN', 'ROYAL SON', 'New Specs', 'hipe', 'VINCENT CHASE', 'PHENOMENAL', 'PHENOMENAL', 'PIRASO', 'ROZZETTA CRAFT', 'Fastrack', 'Rich Club', 'agera', 'ROZZETTA CRAFT', 'New Specs', 'Elligator', 'Lee Topper', 'AISLIN', 'kingsunglasses', 'Lee Topper', 'Fastrack', 'DEIXELS', 'PIRASO', 'ROZZETTA CRAFT', 'Singco India', 'Singco India', 'Fastrack', 'hipe', 'hipe', 'DEIXELS', 'ROZZETTA CRAFT', 'ROYAL SON', 'Fastrack', 'Singco India', 'Elligator', 'Fastrack', 'SUNBEE', 'VILLAIN', 'ROYAL SON', 'Silver Kartz', 'Fastrack', 'AISLIN', 'Rich Club', 'SRPM', 'ROZZETTA CRAFT', 'AISLIN', 'ROYAL SON', 'PHENOMENAL', 'Lee Topper', 'AISLIN', 'Singco India', 'Rich Club', 'kingsunglasses', 'ROZZETTA CRAFT', 'Elligator', 'ROYAL SON', 'Billion', 'VINCENT CHASE', 'GANSTA', 'PIRASO', 'PIRASO', 'DEIXELS', 'Urbanic', 'PHENOMENAL', 'ROZZETTA CRAFT', 'Singco India', 'kingsunglasses', 'PHENOMENAL', 'Singco', 'Singco India', 'kingsunglasses', 'Rich Club', 'Fastrack', 'DEIXELS', 'Fravy', 'kingsunglasses', 'Silver Kartz', 'Singco India', 'PIRASO', 'Rich Club', 'New Specs', 'AISLIN']\n",
      "\n",
      " \n",
      "Product Description:- \n",
      " ['Gradient, Toughened Glass Lens, UV Protection Retro Squ...', 'UV Protection, Riding Glasses, Others Aviator, Wayfarer...', 'UV Protection Aviator Sunglasses (54)', 'UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Round Sunglasses (54)', 'UV Protection Wayfarer Sunglasses (56)', 'UV Protection Round Sunglasses (54)', 'UV Protection Rectangular Sunglasses (Free Size)', 'UV Protection, Polarized, Mirrored Rectangular Sunglass...', 'UV Protection Aviator Sunglasses (54)', 'Mirrored, UV Protection, Riding Glasses, Others Round S...', 'UV Protection, Gradient Round Sunglasses (58)', 'UV Protection, Polarized, Mirrored Round Sunglasses (Fr...', 'UV Protection Aviator Sunglasses (54)', 'Mirrored Aviator Sunglasses (55)', 'Mirrored, UV Protection Aviator Sunglasses (Free Size)', 'UV Protection Round Sunglasses (Free Size)', 'Mirrored, UV Protection Wayfarer Sunglasses (53)', 'UV Protection, Polarized, Mirrored Rectangular Sunglass...', 'UV Protection, Gradient Cat-eye Sunglasses (58)', 'UV Protection Rectangular Sunglasses (58)', 'UV Protection Rectangular Sunglasses (Free Size)', 'Mirrored, Gradient, UV Protection Aviator Sunglasses (5...', 'by Lenskart UV Protection Wayfarer Sunglasses (49)', 'UV Protection, Mirrored Retro Square Sunglasses (53)', 'UV Protection, Mirrored Retro Square Sunglasses (53)', 'UV Protection Aviator Sunglasses (58)', 'UV Protection, Gradient Rectangular Sunglasses (Free Si...', 'UV Protection Wayfarer Sunglasses (55)', 'UV Protection Round Sunglasses (50)', 'Gradient Aviator Sunglasses (55)', 'UV Protection, Gradient Rectangular Sunglasses (Free Si...', 'UV Protection Round Sunglasses (Free Size)', 'UV Protection Round Sunglasses (53)', 'Riding Glasses, Night Vision Wrap-around Sunglasses (Fr...', 'UV Protection Wayfarer Sunglasses (61)', 'UV Protection, Riding Glasses, Mirrored Wayfarer Sungla...', 'UV Protection Rectangular Sunglasses (Free Size)', 'UV Protection Aviator Sunglasses (Free Size)', 'UV Protection Rectangular Sunglasses (Free Size)', 'UV Protection Butterfly Sunglasses (65)', 'UV Protection, Gradient Round Sunglasses (Free Size)', 'Riding Glasses, UV Protection, Others Aviator Sunglasse...', 'Gradient, Toughened Glass Lens, UV Protection Retro Squ...', 'UV Protection Shield Sunglasses (Free Size)', 'UV Protection, Mirrored, Riding Glasses, Night Vision, ...', 'UV Protection, Gradient, Mirrored, Riding Glasses Aviat...', 'UV Protection Rectangular Sunglasses (Free Size)', 'UV Protection, Gradient Retro Square Sunglasses (Free S...', 'UV Protection, Gradient Butterfly Sunglasses (57)', 'Polarized Retro Square Sunglasses (Free Size)', 'Mirrored, Riding Glasses, Others Sports Sunglasses (50)', 'UV Protection Retro Square, Round Sunglasses (54)', 'UV Protection Aviator Sunglasses (58)', 'UV Protection, Polarized, Mirrored Retro Square Sunglas...', 'Others Retro Square Sunglasses (Free Size)', 'Mirrored Aviator Sunglasses (55)', 'UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Aviator Sunglasses (Free Size)', 'UV Protection, Gradient Round Sunglasses (58)', 'Polarized Round Sunglasses (48)', 'UV Protection Wayfarer Sunglasses (53)', 'UV Protection, Gradient Rectangular Sunglasses (Free Si...', 'UV Protection, Gradient Cat-eye Sunglasses (58)', 'Mirrored Aviator Sunglasses (55)', 'UV Protection, Mirrored Clubmaster Sunglasses (Free Siz...', 'UV Protection, Riding Glasses Retro Square, Spectacle ...', 'UV Protection Wayfarer Sunglasses (61)', 'UV Protection, Riding Glasses, Others Aviator, Wayfarer...', 'UV Protection Round Sunglasses (48)', 'Mirrored, UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection, Gradient Rectangular Sunglasses (Free Si...', 'UV Protection Round Sunglasses (55)', 'UV Protection Retro Square Sunglasses (58)', 'UV Protection Aviator Sunglasses (57)', 'by Lenskart UV Protection Wayfarer Sunglasses (49)', 'UV Protection, Riding Glasses Wayfarer Sunglasses (53)', 'UV Protection Aviator Sunglasses (Free Size)', 'UV Protection Aviator Sunglasses (54)', 'UV Protection Rectangular Sunglasses (Free Size)', 'Others Retro Square Sunglasses (Free Size)', 'UV Protection Clubmaster Sunglasses (Free Size)', 'UV Protection, Gradient Round Sunglasses (Free Size)', 'Gradient, Toughened Glass Lens, UV Protection Retro Squ...', 'Mirrored, UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Retro Square Sunglasses (Free Size)', 'UV Protection Aviator Sunglasses (Free Size)', 'UV Protection, Riding Glasses, Others Aviator, Wayfarer...', 'Mirrored, UV Protection Aviator Sunglasses (56)', 'UV Protection, Others Round Sunglasses (48)', 'UV Protection Round Sunglasses (55)', 'UV Protection Rectangular Sunglasses (Free Size)', 'UV Protection, Gradient, Night Vision Retro Square Sung...', 'UV Protection, Mirrored Round Sunglasses (Free Size)', 'UV Protection Aviator Sunglasses (88)', 'Mirrored, Riding Glasses, Others Sports Sunglasses (50)', 'Mirrored Aviator Sunglasses (32)', 'UV Protection, Polarized Oval Sunglasses (48)', 'UV Protection Rectangular Sunglasses (Free Size)', 'UV Protection, Gradient Round Sunglasses (58)']\n",
      "\n",
      " \n",
      " Price:- \n",
      " ['₹599', '₹229', '₹200', '₹759', '₹248', '₹198', '₹188', '₹319', '₹165', '₹200', '₹262', '₹498', '₹271', '₹200', '₹359', '₹1,499', '₹289', '₹273', '₹181', '₹459', '₹449', '₹259', '₹229', '₹1,179', '₹299', '₹299', '₹299', '₹348', '₹549', '₹355', '₹196', '₹353', '₹233', '₹189', '₹276', '₹698', '₹187', '₹199', '₹575', '₹319', '₹349', '₹360', '₹201', '₹599', '₹789', '₹179', '₹209', '₹319', '₹349', '₹664', '₹639', '₹220', '₹291', '₹1,089', '₹227', '₹549', '₹359', '₹246', '₹639', '₹498', '₹163', '₹207', '₹348', '₹459', '₹359', '₹287', '₹375', '₹698', '₹229', '₹220', '₹256', '₹353', '₹239', '₹449', '₹224', '₹1,179', '₹209', '₹299', '₹200', '₹319', '₹499', '₹287', '₹426', '₹599', '₹256', '₹309', '₹498', '₹229', '₹211', '₹220', '₹899', '₹319', '₹245', '₹235', '₹255', '₹220', '₹164', '₹175', '₹168', '₹498']\n",
      "\n",
      " \n",
      " Discount:- \n",
      " ['80% off', '67% off', '87% off', '15% off', '90% off', '84% off', '81% off', '78% off', '90% off', '87% off', '83% off', '67% off', '84% off', '87% off', '76% off', '81% off', '81% off', '86% off', '81% off', '69% off', '70% off', '87% off', '81% off', '41% off', '85% off', '85% off', '88% off', '84% off', '31% off', '64% off', '82% off', '82% off', '82% off', '87% off', '88% off', '74% off', '84% off', '80% off', '28% off', '78% off', '86% off', '81% off', '86% off', '80% off', '12% off', '87% off', '79% off', '78% off', '82% off', '66% off', '20% off', '85% off', '85% off', '16% off', '82% off', '26% off', '76% off', '83% off', '20% off', '67% off', '67% off', '79% off', '84% off', '69% off', '76% off', '85% off', '71% off', '74% off', '67% off', '72% off', '87% off', '82% off', '88% off', '70% off', '77% off', '41% off', '88% off', '81% off', '87% off', '78% off', '36% off', '85% off', '78% off', '80% off', '82% off', '84% off', '75% off', '67% off', '83% off', '72% off', '10% off', '78% off', '87% off', '86% off', '78% off', '85% off', '89% off', '64% off', '88% off', '67% off']\n"
     ]
    }
   ],
   "source": [
    "print('\\n List of Brands:- \\n', b)\n",
    "print('\\n \\nProduct Description:- \\n', d)\n",
    "print('\\n \\n Price:- \\n', p)\n",
    "print('\\n \\n Discount:- \\n', o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45e5bc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>UV Protection, Riding Glasses, Others Aviator,...</td>\n",
       "      <td>₹229</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹200</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹759</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹248</td>\n",
       "      <td>90% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Mirrored, Riding Glasses, Others Sports Sungla...</td>\n",
       "      <td>₹220</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>Mirrored Aviator Sunglasses (32)</td>\n",
       "      <td>₹164</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>UV Protection, Polarized Oval Sunglasses (48)</td>\n",
       "      <td>₹175</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹168</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (58)</td>\n",
       "      <td>₹498</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                Product Description Price  \\\n",
       "0   Singco India  Gradient, Toughened Glass Lens, UV Protection ...  ₹599   \n",
       "1   Singco India  UV Protection, Riding Glasses, Others Aviator,...  ₹229   \n",
       "2         PIRASO              UV Protection Aviator Sunglasses (54)  ₹200   \n",
       "3       Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹759   \n",
       "4      Elligator                UV Protection Round Sunglasses (54)  ₹248   \n",
       "..           ...                                                ...   ...   \n",
       "95  Singco India  Mirrored, Riding Glasses, Others Sports Sungla...  ₹220   \n",
       "96        PIRASO                   Mirrored Aviator Sunglasses (32)  ₹164   \n",
       "97     Rich Club      UV Protection, Polarized Oval Sunglasses (48)  ₹175   \n",
       "98     New Specs   UV Protection Rectangular Sunglasses (Free Size)  ₹168   \n",
       "99        AISLIN      UV Protection, Gradient Round Sunglasses (58)  ₹498   \n",
       "\n",
       "   Discount  \n",
       "0   80% off  \n",
       "1   67% off  \n",
       "2   87% off  \n",
       "3   15% off  \n",
       "4   90% off  \n",
       "..      ...  \n",
       "95  85% off  \n",
       "96  89% off  \n",
       "97  64% off  \n",
       "98  88% off  \n",
       "99  67% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.DataFrame() \n",
    "df3['Brand']=b\n",
    "df3['Product Description'] = d\n",
    "df3['Price']=p\n",
    "df3['Discount']=o\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "090b7a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3. to_csv('product.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473668b2",
   "metadata": {},
   "source": [
    "## Ques 5\n",
    "Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\n",
    "\n",
    "You have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ce10c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 = 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace'\n",
    "driver.get(url4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e5528",
   "metadata": {},
   "source": [
    " All Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a374b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "next = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a/div/span')\n",
    "next.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49c96d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=11\n",
    "rating = []\n",
    "review = []\n",
    "full = []\n",
    "for page in range(start,end):\n",
    "    ratings=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    reviews=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    descp=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    for i in ratings:\n",
    "        rating.append(i.text)\n",
    "    for j in reviews:\n",
    "        review.append(j.text)\n",
    "    for k in descp:\n",
    "        full.append(k.text)\n",
    "        \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23dfdd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr=rating[0:100]\n",
    "re=review[0:100]\n",
    "ff=full[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ec31d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>The ultimate performance\\nCamera is superb\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>I use a Note10+ and have been using both iOS a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good\\nAs far as camera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice value for money good and best price I pho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings              Reviews  \\\n",
       "0        5            Brilliant   \n",
       "1        5       Simply awesome   \n",
       "2        5     Perfect product!   \n",
       "3        5  Best in the market!   \n",
       "4        5    Worth every penny   \n",
       "..     ...                  ...   \n",
       "95       3            Just wow!   \n",
       "96       5    Terrific purchase   \n",
       "97       5              Awesome   \n",
       "98       5       Decent product   \n",
       "99       5            Wonderful   \n",
       "\n",
       "                                          Description  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Great iPhone very snappy experience as apple k...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  The ultimate performance\\nCamera is superb\\nTh...  \n",
       "96  I use a Note10+ and have been using both iOS a...  \n",
       "97  The phone is completely good\\nAs far as camera...  \n",
       "98  Everything u ll like it when u use this iPhone...  \n",
       "99  Nice value for money good and best price I pho...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.DataFrame({'Ratings':rr,'Reviews':re,'Description':ff})\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88725f3",
   "metadata": {},
   "source": [
    "## Ques 6\n",
    "Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c72acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "url5 = 'https://www.flipkart.com/'\n",
    "driver.get(url5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a385ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_class_name(\"_3704LK\")\n",
    "search.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "898e3b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_class_name('L0Z3Pu')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e6704fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "start=0\n",
    "end=3\n",
    "brand1 = []\n",
    "price1 = []\n",
    "des1 = []\n",
    "for page in range(start,end): #for loop for scrapping 3 page\n",
    "    brands1=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    prices1=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    descp1=driver.find_elements_by_class_name('IRpwTa')\n",
    "\n",
    "    for i in brands1:\n",
    "        brand1.append(i.text) #appending the text in Brands1 list\n",
    "    for j in prices1:\n",
    "        price1.append(j.text)\n",
    "    for k in descp1:\n",
    "        des1.append(k.text)\n",
    "        \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "print(len(brand1))\n",
    "print(len(price1))\n",
    "print(len(des1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66faa178",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb=brand1[0:100]\n",
    "pp=price1[0:100]\n",
    "dd=des1[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ca4f269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Echor Men's Sneakers Fashion Lightweight Runni...</td>\n",
       "      <td>₹569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Classic Sneakers For Men</td>\n",
       "      <td>₹1,678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Tying</td>\n",
       "      <td>Model name: New Latest Affordable Range of Com...</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RODDICK SHOES</td>\n",
       "      <td>Fashion Outdoor Canvas Casual Light Weight Lac...</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Rocky Footwear</td>\n",
       "      <td>Stylish Premium Casual Sneakers for Men (Red) ...</td>\n",
       "      <td>₹422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>leo shoes</td>\n",
       "      <td>Leo Men's Light Weight Knitted Mesh Multicolor...</td>\n",
       "      <td>₹749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product Description   Price\n",
       "0            Echor  Echor Men's Sneakers Fashion Lightweight Runni...    ₹569\n",
       "1         RED TAPE                           Classic Sneakers For Men  ₹1,678\n",
       "2         Magnolia                                   Sneakers For Men    ₹398\n",
       "3           Labbin                                   Sneakers For Men    ₹499\n",
       "4   luxury fashion  Luxury Fashionable casual sneaker shoes Sneake...    ₹449\n",
       "..             ...                                                ...     ...\n",
       "95        RED TAPE                                   Sneakers For Men  ₹1,258\n",
       "96           Tying  Model name: New Latest Affordable Range of Com...    ₹999\n",
       "97   RODDICK SHOES  Fashion Outdoor Canvas Casual Light Weight Lac...    ₹499\n",
       "98  Rocky Footwear  Stylish Premium Casual Sneakers for Men (Red) ...    ₹422\n",
       "99       leo shoes  Leo Men's Light Weight Knitted Mesh Multicolor...    ₹749\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=pd.DataFrame()\n",
    "df5['Brand']=bb\n",
    "df5['Product Description'] = dd\n",
    "df5['Price']=pp\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff2f477",
   "metadata": {},
   "source": [
    "## Ques 7\n",
    "Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, and then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f23c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url6 = 'https://www.myntra.com/shoes'\n",
    "driver.get(url6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08f6d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#color check\n",
    "col = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "col.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "991e05a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#price check\n",
    "price_check = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "price_check.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1acfb9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "150\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "start=0\n",
    "end=3\n",
    "brand2 = []\n",
    "price2 = []\n",
    "des2 = []\n",
    "\n",
    "for page in range(start,end): #for loop for scrapping 3 page\n",
    "    brands2=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\") #scraping brands name by xpath\n",
    "    prices2=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    descp2=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "\n",
    "    for i in brands2:\n",
    "        brand2.append(i.text) #appending the text in Brands2\n",
    "    for j in prices2:\n",
    "        price2.append(j.text)\n",
    "    for k in descp2:\n",
    "        des2.append(k.text)\n",
    "\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@rel='next']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "print(len(brand2))\n",
    "print(len(price2))\n",
    "print(len(des2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "973cdf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb= brand2[0:100]\n",
    "ppp=price2[0:100]\n",
    "ddd=des2[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb18eb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short Shoe Description</th>\n",
       "      <th>Price of the Shoe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Magnify Nitro Running</td>\n",
       "      <td>Rs. 7799Rs. 12999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Men Mid-Top Chelsea Boots</td>\n",
       "      <td>Rs. 9265Rs. 10900(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delize</td>\n",
       "      <td>Block Heeled Boots</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td>Men Textured Formal Loafers</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Men Textured Formal Leather Loafers</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Kitten Heeled Boots</td>\n",
       "      <td>Rs. 7565Rs. 8900(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men GO RUN RIDE 9 RunningShoes</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Solid Leather Formal Penny Loafers</td>\n",
       "      <td>Rs. 7693Rs. 10990(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>Rs. 8799Rs. 10999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Leather Heeled Boots</td>\n",
       "      <td>Rs. 12325Rs. 14500(15% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand                  Short Shoe Description  \\\n",
       "0                   Puma               Men Magnify Nitro Running   \n",
       "1                Saint G               Men Mid-Top Chelsea Boots   \n",
       "2                 Delize                      Block Heeled Boots   \n",
       "3         ROSSO BRUNELLO             Men Textured Formal Loafers   \n",
       "4               DAVINCHI     Men Textured Formal Leather Loafers   \n",
       "..                   ...                                     ...   \n",
       "95               Saint G               Women Kitten Heeled Boots   \n",
       "96              Skechers          Men GO RUN RIDE 9 RunningShoes   \n",
       "97  Heel & Buckle London  Men Solid Leather Formal Penny Loafers   \n",
       "98               Bugatti                            Men Sneakers   \n",
       "99               Saint G              Women Leather Heeled Boots   \n",
       "\n",
       "              Price of the Shoe  \n",
       "0    Rs. 7799Rs. 12999(40% OFF)  \n",
       "1    Rs. 9265Rs. 10900(15% OFF)  \n",
       "2                      Rs. 9999  \n",
       "3                     Rs. 10999  \n",
       "4                      Rs. 8990  \n",
       "..                          ...  \n",
       "95    Rs. 7565Rs. 8900(15% OFF)  \n",
       "96                    Rs. 10999  \n",
       "97   Rs. 7693Rs. 10990(30% OFF)  \n",
       "98   Rs. 8799Rs. 10999(20% OFF)  \n",
       "99  Rs. 12325Rs. 14500(15% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.DataFrame()\n",
    "df6['Brand']=bbb\n",
    "df6['Short Shoe Description'] = ddd\n",
    "df6['Price of the Shoe'] = ppp\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc29b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df6. to_csv('Shoes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e303cd",
   "metadata": {},
   "source": [
    "## Ques 8\n",
    "Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df7e6596",
   "metadata": {},
   "outputs": [],
   "source": [
    "url7 = 'https://www.amazon.in/'\n",
    "driver.get(url7) #opening the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0df783c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "search.send_keys('Laptop') #Sending the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26053dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "butt=driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "butt.click() #clicking on the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9bdfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "see_more=driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/div/div/div[1]/div/span[2]/a/span')\n",
    "see_more.click() #Clicking on see more option on the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c9109ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "i7=driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/div/div/div[1]/div/span[1]/a[12]/div')\n",
    "i7.click() # Currectly Check box was not available here in the website so, first scrapping data for i7 then for i9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2435d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping the price for 1st 10 laptop's\n",
    "pri = []\n",
    "pric=driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "for i in pric:\n",
    "    pri.append(i.text) #appending text\n",
    "p= pri[0:10] #Fixing the limit(only 10 laptops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0820d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locating the url's for each laptop's\n",
    "urls=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']/a\")\n",
    "UR=[]\n",
    "for i in urls[0:10]:\n",
    "    UR.append(i.get_attribute('href')) #getting the url of first 10 laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36c348d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "rating=[]\n",
    "nam = []\n",
    "\n",
    "for i in UR:    \n",
    "    try:   #here i used try and except because there were few laptops where ratings were not there in the website\n",
    "        driver.get(i)\n",
    "        rate=driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']\")\n",
    "        rating.append(rate.text)\n",
    "    except NoSuchElementException:\n",
    "        rating.append(\"NO rating\")\n",
    "\n",
    "for j in UR:\n",
    "    try:\n",
    "        driver.get(j)\n",
    "        name=driver.find_element_by_xpath('//span[@class=\"a-size-large product-title-word-break\"]')\n",
    "        nam.append(name.text.split(',')[0].replace(',','\\n'))\n",
    "    except NoSuchElementException:\n",
    "        rating.append(\"No Title available\")\n",
    "\n",
    "print(len(rating))\n",
    "print(len(nam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "028c38e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Name Of Laptop's :-\n",
      " \n",
      " ['Lenovo IdeaPad Slim 5 11th Gen Intel Core i5 15.6\"(39.62cm) FHD IPS Thin & Light Laptop (16GB/512GB SSD/Windows 11/MS Office 2021/Backlit Keyboard/Fingerprint Reader/Graphite Grey/1.66Kg)', 'Mi Notebook Ultra 3.2K resolution display Intel Core i5-11300H 11th Gen 15.6-inch(39.62 cm) Thin and Light laptop (16GB/512GB SSD/Iris Xe Graphics/Win 10/MS Office/Backlit KB/Fingerprint sensor/1.7Kg)', 'Lenovo IdeaPad Gaming 3 10th Gen Intel i5 15.6\" FHD Laptop (8GB/1TB HDD/GTX 1650 4GB GDDR6 Graphics/60Hz Refresh Rate/Windows 10/Office 2019/Blue Backlit/Onyx Black/2.2Kg)', 'ASUS TUF Gaming F15', 'Lenovo IdeaPad Slim 5 11th Gen Intel Core i5 15.6\"(39.62cm) FHD IPS Thin & Light Laptop (16GB/512GB SSD/Windows 11/MS Office 2021/Backlit Keyboard/Fingerprint Reader/Graphite Grey/1.66Kg)', 'Mi Notebook Ultra 3.2K resolution display Intel Core i5-11300H 11th Gen 15.6-inch(39.62 cm) Thin and Light laptop (16GB/512GB SSD/Iris Xe Graphics/Win 10/MS Office/Backlit KB/Fingerprint sensor/1.7Kg)', 'Lenovo IdeaPad 3 10th Gen Intel Core i5 15.6 FHD Thin and Light Laptop (8GB/512GB SDD/Windows 11/MS Office 2021/2Yr Warranty/Platinum Grey/1.85Kg)', '(Renewed) Hp ProBook 640 G1 4TH Gen Core i5 Laptop', 'HP Pavilion 14', 'HP Pavilion 14']\n",
      "\n",
      "\n",
      " Rating's of Each Laptop :- \n",
      " \n",
      " ['4.3 out of 5', '4.3 out of 5', '4 out of 5', '4.4 out of 5', '4.3 out of 5', '4.3 out of 5', '4.2 out of 5', 'NO rating', '5 out of 5', '4.4 out of 5']\n",
      "\n",
      "\n",
      " Price of Laptop's :- \n",
      " \n",
      " ['62,990', '63,499', '49,990', '58,990', '62,990', '63,499', '49,990', '24,499', '61,990', '67,990']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Name Of Laptop's :-\\n \\n\", nam )\n",
    "print(\"\\n\\n Rating's of Each Laptop :- \\n \\n\", rating)\n",
    "print(\"\\n\\n Price of Laptop's :- \\n \\n\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5313415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of laptops</th>\n",
       "      <th>Ratings of the Laptops</th>\n",
       "      <th>Price of the Laptops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 11th Gen Intel Core i5 1...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi Notebook Ultra 3.2K resolution display Inte...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>63,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 10th Gen Intel i5 15.6...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS TUF Gaming F15</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>58,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 11th Gen Intel Core i5 1...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mi Notebook Ultra 3.2K resolution display Inte...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>63,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad 3 10th Gen Intel Core i5 15.6 F...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Hp ProBook 640 G1 4TH Gen Core i5 La...</td>\n",
       "      <td>NO rating</td>\n",
       "      <td>24,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion 14</td>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>61,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion 14</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>67,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name of laptops Ratings of the Laptops  \\\n",
       "0  Lenovo IdeaPad Slim 5 11th Gen Intel Core i5 1...           4.3 out of 5   \n",
       "1  Mi Notebook Ultra 3.2K resolution display Inte...           4.3 out of 5   \n",
       "2  Lenovo IdeaPad Gaming 3 10th Gen Intel i5 15.6...             4 out of 5   \n",
       "3                                ASUS TUF Gaming F15           4.4 out of 5   \n",
       "4  Lenovo IdeaPad Slim 5 11th Gen Intel Core i5 1...           4.3 out of 5   \n",
       "5  Mi Notebook Ultra 3.2K resolution display Inte...           4.3 out of 5   \n",
       "6  Lenovo IdeaPad 3 10th Gen Intel Core i5 15.6 F...           4.2 out of 5   \n",
       "7  (Renewed) Hp ProBook 640 G1 4TH Gen Core i5 La...              NO rating   \n",
       "8                                     HP Pavilion 14             5 out of 5   \n",
       "9                                     HP Pavilion 14           4.4 out of 5   \n",
       "\n",
       "  Price of the Laptops  \n",
       "0               62,990  \n",
       "1               63,499  \n",
       "2               49,990  \n",
       "3               58,990  \n",
       "4               62,990  \n",
       "5               63,499  \n",
       "6               49,990  \n",
       "7               24,499  \n",
       "8               61,990  \n",
       "9               67,990  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = pd.DataFrame({'Name of laptops':nam,'Ratings of the Laptops':rating,'Price of the Laptops':p})\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3eeaa1",
   "metadata": {},
   "source": [
    "## Now scapping data for i9 as check box was not available, so scrapping i9 seperatly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a916e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "url07 = 'https://www.amazon.in/' \n",
    "driver.get(url07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "24b58b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "search.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "043db837",
   "metadata": {},
   "outputs": [],
   "source": [
    "butt=driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "butt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f90dda90",
   "metadata": {},
   "outputs": [],
   "source": [
    "see_more=driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/div/div/div[1]/div/span[2]/a/span')\n",
    "see_more.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45a75043",
   "metadata": {},
   "outputs": [],
   "source": [
    "i9=driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/div/div/div[1]/div/span[1]/a[14]/div/span')\n",
    "i9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d8e76b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping the price for 1st 10 laptop's\n",
    "pri = []\n",
    "pric=driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "for i in pric:\n",
    "    pri.append(i.text) #appending text\n",
    "p= pri[0:10] #Fixing the limit(only 10 laptops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d0d0e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the url's.\n",
    "urls=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']/a\")\n",
    "UR=[]\n",
    "for i in urls[0:10]: #There are only 2 products whose ratings are there\n",
    "    UR.append(i.get_attribute('href'))#getting the url of first 4 laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b59b2787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "rating=[]\n",
    "tit = []\n",
    "\n",
    "for i in UR:    \n",
    "    try:\n",
    "        driver.get(i)\n",
    "        rate=driver.find_element_by_xpath('//span[@class=\"a-size-base a-nowrap\"]')\n",
    "        rating.append(rate.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        rating.append(\"No Rating Availabe\")\n",
    "        \n",
    "for j in UR:\n",
    "    try:\n",
    "        driver.get(j)\n",
    "        titl=driver.find_element_by_xpath('//span[@class=\"a-size-large product-title-word-break\"]')\n",
    "        tit.append(titl.text.replace(',','\\n'))\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        tit.append(\"No title available\")\n",
    "        \n",
    "print(len(tit))\n",
    "print(len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a27d7974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Name Of Laptop's :-\n",
      " \n",
      " ['ASUS TUF Gaming F15 (2021)\\n 15.6\" (39.62 cms) FHD 240Hz\\n Intel Core i9-11900H 11th Gen\\n GeForce RTX 3060 6GB Graphics\\n Gaming Laptop(16GB/1TB SSD/Office 2019/Windows 10/Gray/2.3 Kg)\\n FX566HM-AZ096TS', 'ASUS TUF Gaming F15 (2021)\\n 15.6-inch (39.62 cms) FHD 240Hz/3ms\\n Intel Core i9-11900H 11th Gen\\n RTX 3060 6GB Graphics Gaming Laptop (16GB/1TB SSD/Office 2019/Windows 10/Black/2.3 kg)\\n FX506HM-AZ099TS', 'Dell Precision 5550 || i9 -10885H || 16GB || 1TB NVMe || T2000 4 GB || Win 10 Pro (Free Upgrade Win 11Pro) / 15.6 FHD+ / 3 Year ADP', 'ASUS TUF Gaming F15 (2021)\\n 15.6-inch (39.62 cms) FHD 144Hz\\n Intel Core i9-11900H 11th Gen\\n RTX 3060 6GB Graphics Gaming Laptop (16GB RAM/1TB SSD/Office 2019/Windows 10/Gray/2.3 kg)\\n FX566HM-HN097TS', 'Lenovo Legion 7 10th Gen Intel Core i9 15.6 inch Full HD Gaming Laptop (16GB/1TB SSD/Windows 10/MS Office 2019/144 Hz/NVIDIA RTX 2080 8GB GDDR6 Graphics/Slate Grey/2.25Kg)\\n 81YU006HIN', 'ASUS ROG Strix Scar III G531GW 15.6\" FHD 240Hz Gaming Laptop RTX 2070 8GB Graphics (Core i9-9880H 9th Gen/32GB RAM/1TB PCIe SSD/Windows 10/Scar Gunmetal/2.57 Kg)\\n G531GW-AZ113T', '(Renewed) Dell G7 7500 15.6inch FHD 300 Hz Display Gaming Laptop (10th Gen i9-10885H / 16 GB / 1TB SSD / NVIDIA RTX 2070 8GB Graphics / 1Yr Premium Warranty / Win 10 + MS Office H&S 2019) D560233WIN9B\\n Black', 'HP ZBOOK Power G8/ Intel core i9-11900H 8 Core/32GB DDR4 3200 RAM/1TB PCIe NVMe TLC SSD /15.6” FHD /Nvidia Quadro T1200 Dedicated Graphics 4GB DDR6 /Windows 10 Pro / 3 Year Warranty', 'Z2 G5 Workstation 700W /Core i9-10900 (2.8GHz 10C) /16GB RAM/512GB SSD+1TB SATA/Nvidia RTX 3070 8GB Graphics/DVDRW/Windows 10 Pro/3 Year Warranty', 'BZ MB WS ZB/Power G8/DSC i9-11900H/32GB/SSD1TB/NVQ A2000/400FHD/IR/Win10 Pro']\n",
      "\n",
      "\n",
      " Rating's of Each Laptop :- \n",
      " \n",
      " ['4.1 out of 5', '4.1 out of 5', 'No Rating Availabe', '5 out of 5', '4.4 out of 5', '5 out of 5', 'No Rating Availabe', 'No Rating Availabe', 'No Rating Availabe', 'No Rating Availabe']\n",
      "\n",
      "\n",
      " Price of Laptop's :- \n",
      " \n",
      " ['1,44,990', '1,43,990', '2,00,000', '1,39,990', '2,65,999', '1,89,000', '2,25,000', '2,45,000', '2,39,000', '2,57,729']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Name Of Laptop's :-\\n \\n\", tit )\n",
    "print(\"\\n\\n Rating's of Each Laptop :- \\n \\n\", rating)\n",
    "print(\"\\n\\n Price of Laptop's :- \\n \\n\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ec7a67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of laptops(i9)</th>\n",
       "      <th>Ratings of the Laptops</th>\n",
       "      <th>Price of the Laptops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021)\\n 15.6\" (39.62 cms)...</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>1,44,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021)\\n 15.6-inch (39.62 ...</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>1,43,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dell Precision 5550 || i9 -10885H || 16GB || 1...</td>\n",
       "      <td>No Rating Availabe</td>\n",
       "      <td>2,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021)\\n 15.6-inch (39.62 ...</td>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>1,39,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>2,65,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS ROG Strix Scar III G531GW 15.6\" FHD 240Hz...</td>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>1,89,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) Dell G7 7500 15.6inch FHD 300 Hz Dis...</td>\n",
       "      <td>No Rating Availabe</td>\n",
       "      <td>2,25,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP ZBOOK Power G8/ Intel core i9-11900H 8 Core...</td>\n",
       "      <td>No Rating Availabe</td>\n",
       "      <td>2,45,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Z2 G5 Workstation 700W /Core i9-10900 (2.8GHz ...</td>\n",
       "      <td>No Rating Availabe</td>\n",
       "      <td>2,39,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BZ MB WS ZB/Power G8/DSC i9-11900H/32GB/SSD1TB...</td>\n",
       "      <td>No Rating Availabe</td>\n",
       "      <td>2,57,729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Name of laptops(i9) Ratings of the Laptops  \\\n",
       "0  ASUS TUF Gaming F15 (2021)\\n 15.6\" (39.62 cms)...           4.1 out of 5   \n",
       "1  ASUS TUF Gaming F15 (2021)\\n 15.6-inch (39.62 ...           4.1 out of 5   \n",
       "2  Dell Precision 5550 || i9 -10885H || 16GB || 1...     No Rating Availabe   \n",
       "3  ASUS TUF Gaming F15 (2021)\\n 15.6-inch (39.62 ...             5 out of 5   \n",
       "4  Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...           4.4 out of 5   \n",
       "5  ASUS ROG Strix Scar III G531GW 15.6\" FHD 240Hz...             5 out of 5   \n",
       "6  (Renewed) Dell G7 7500 15.6inch FHD 300 Hz Dis...     No Rating Availabe   \n",
       "7  HP ZBOOK Power G8/ Intel core i9-11900H 8 Core...     No Rating Availabe   \n",
       "8  Z2 G5 Workstation 700W /Core i9-10900 (2.8GHz ...     No Rating Availabe   \n",
       "9  BZ MB WS ZB/Power G8/DSC i9-11900H/32GB/SSD1TB...     No Rating Availabe   \n",
       "\n",
       "  Price of the Laptops  \n",
       "0             1,44,990  \n",
       "1             1,43,990  \n",
       "2             2,00,000  \n",
       "3             1,39,990  \n",
       "4             2,65,999  \n",
       "5             1,89,000  \n",
       "6             2,25,000  \n",
       "7             2,45,000  \n",
       "8             2,39,000  \n",
       "9             2,57,729  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df07 = pd.DataFrame({'Name of laptops(i9)':tit,'Ratings of the Laptops':rating,'Price of the Laptops':p})\n",
    "df07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a34e16a",
   "metadata": {},
   "source": [
    "## Ques 9\n",
    "Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "944e6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "url8 = 'https://www.ambitionbox.com/'\n",
    "driver.get(url8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ad2574ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "job= driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[6]')\n",
    "job.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9c13ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sear = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div/div/div/div/span/input')\n",
    "sear.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4678e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "butto=driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div/div/div/button/span')\n",
    "butto.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5de7a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "loca=driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[1]/p')\n",
    "loca.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "beb094d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ty=driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "ty.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c8d0f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cli=driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "cli.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "38f729a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "20\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "heading = []\n",
    "names = []\n",
    "days = []\n",
    "ratings = []\n",
    "head=driver.find_elements_by_xpath(\"//a[@class='title noclick']\")#scraping brands name by class name='_2WkVRV'\n",
    "name=driver.find_elements_by_xpath(\"//p[@class='company body-medium']\")\n",
    "day =driver.find_elements_by_xpath(\"//span[@class='body-small-l']\")\n",
    "rat =driver.find_elements_by_xpath(\"//span[@class='body-small']\")\n",
    "for i in head:\n",
    "    heading.append(i.text)\n",
    "for j in name:\n",
    "    names.append(j.text)\n",
    "for k in day:\n",
    "    days.append(k.text)\n",
    "for l in rat:\n",
    "    ratings.append(l.text)\n",
    "print(len(heading))\n",
    "print(len(names))\n",
    "print(len(days))\n",
    "print(len(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee00f24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HCL',\n",
       " 'Jubilant Foodworks Limited',\n",
       " 'Ameriprise Financial',\n",
       " 'Paytm',\n",
       " 'CHT Sapiense',\n",
       " 'CHT Sapiense',\n",
       " 'GI Group',\n",
       " 'GI Group',\n",
       " 'GI Group',\n",
       " 'Cargoflash']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "24688e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HCL - Data Scientist - NLP/Python (2-6 yrs)',\n",
       " 'Data Scientist',\n",
       " 'Manager Data Scientist',\n",
       " 'Vice President - Data Science',\n",
       " 'CogniTensor - Data Scientist (2-5 yrs)',\n",
       " 'CogniTensor - Data Scientist (2-5 yrs)',\n",
       " 'Data Scientist - Data Science/Model Development (0-6 yrs)',\n",
       " 'Manager - Data Scientist - Retail/BFSI (8-15 yrs)',\n",
       " 'Data Scientist - Consulting Firm (8-15 yrs)',\n",
       " 'Cargo Flash - Operation Research Analyst - Revenue Management System (3-9 yrs)']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3125c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2d ago',\n",
       " '2d ago',\n",
       " '4d ago',\n",
       " '10d ago',\n",
       " '11d ago',\n",
       " '12d ago',\n",
       " '23d ago',\n",
       " '23d ago',\n",
       " '23d ago',\n",
       " '1d ago']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=days[0:20:2]#Extracting the required data\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0af6aba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.8', '3.9', '4.0', '3.7', '3.8', '3.8', '4.1', '4.1', '4.1', '3.8']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "92dec837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of days ago when job was posted</th>\n",
       "      <th>Rating of the company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HCL</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jubilant Foodworks Limited</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ameriprise Financial</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paytm</td>\n",
       "      <td>10d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHT Sapiense</td>\n",
       "      <td>11d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHT Sapiense</td>\n",
       "      <td>12d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>23d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>23d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>23d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cargoflash</td>\n",
       "      <td>1d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company Name No. of days ago when job was posted  \\\n",
       "0                         HCL                              2d ago   \n",
       "1  Jubilant Foodworks Limited                              2d ago   \n",
       "2        Ameriprise Financial                              4d ago   \n",
       "3                       Paytm                             10d ago   \n",
       "4                CHT Sapiense                             11d ago   \n",
       "5                CHT Sapiense                             12d ago   \n",
       "6                    GI Group                             23d ago   \n",
       "7                    GI Group                             23d ago   \n",
       "8                    GI Group                             23d ago   \n",
       "9                  Cargoflash                              1d ago   \n",
       "\n",
       "  Rating of the company  \n",
       "0                   3.8  \n",
       "1                   3.9  \n",
       "2                   4.0  \n",
       "3                   3.7  \n",
       "4                   3.8  \n",
       "5                   3.8  \n",
       "6                   4.1  \n",
       "7                   4.1  \n",
       "8                   4.1  \n",
       "9                   3.8  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8 =pd.DataFrame()\n",
    "df8['Company Name'] = names\n",
    "df8['No. of days ago when job was posted'] = d\n",
    "df8['Rating of the company'] = ratings\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dfe4b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df8. to_csv('ambition')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056ed382",
   "metadata": {},
   "source": [
    "##  Ques 10\n",
    "Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "018ceace",
   "metadata": {},
   "outputs": [],
   "source": [
    "url9 = 'https://www.ambitionbox.com/'\n",
    "driver.get(url9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1f880ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[4]')\n",
    "sal.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "83544240",
   "metadata": {},
   "outputs": [],
   "source": [
    "sea=driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "sea.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6b767a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc=driver.find_element_by_xpath(\"//div[@class='suggestion']\")\n",
    "cc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c29b8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = []\n",
    "minn = []\n",
    "maax = []\n",
    "avg = []\n",
    "bas = []\n",
    "exp = []\n",
    "\n",
    "sall= driver.find_elements_by_class_name('name') #scraping by class name\n",
    "miin = driver.find_elements_by_class_name('salary-values')\n",
    "mixx= driver.find_elements_by_class_name('salary-values')\n",
    "avgg= driver.find_elements_by_class_name('averageCtc')\n",
    "base= driver.find_elements_by_class_name('name')\n",
    "expp= driver.find_elements_by_xpath('//div[@class=\"salaries sbold-list-header\"]')\n",
    "\n",
    "for i in sall:\n",
    "    sal.append(i.text.split('\\n')[0])  #Spliting the data and fetching the required data what we want.\n",
    "for j in miin:\n",
    "    minn.append(j.text.split('\\n')[0])\n",
    "for k in mixx:\n",
    "    maax.append(k.text.split('\\n')[1])\n",
    "for l in avgg:\n",
    "    avg.append(l.text)\n",
    "\n",
    "for m in base:\n",
    "    bas.append(m.text.split('\\n')[-1])\n",
    "b =bas[0:10]\n",
    "for n in expp:\n",
    "    exp.append(n.text.split('\\n')[-1])\n",
    "    \n",
    "s= sal[0:10] #Fixing the limit of the data that we want\n",
    "mx = maax[0:10]\n",
    "mi = minn[0:10]\n",
    "a = avg[0:10]\n",
    "e=exp[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3692e7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Number of salaries</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 17.7L</td>\n",
       "      <td>₹ 28.7L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>3 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 22 salaries</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 19.5L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 15.8L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 72 salaries</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 23 salaries</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 21.3L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 49 salaries</td>\n",
       "      <td>₹ 7.2L</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 27 salaries</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 18.5L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>based on 42 salaries</td>\n",
       "      <td>₹ 5.8L</td>\n",
       "      <td>₹ 11.9L</td>\n",
       "      <td>₹ 21.5L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company Name    Number of salaries Minimum Salary  \\\n",
       "0                   Walmart  based on 10 salaries        ₹ 17.7L   \n",
       "1                  Ab Inbev  based on 22 salaries        ₹ 15.0L   \n",
       "2                        ZS  based on 14 salaries         ₹ 9.8L   \n",
       "3         Fractal Analytics  based on 72 salaries         ₹ 9.5L   \n",
       "4                     Optum  based on 23 salaries        ₹ 11.0L   \n",
       "5              UnitedHealth  based on 49 salaries         ₹ 7.2L   \n",
       "6           Tiger Analytics  based on 27 salaries         ₹ 8.3L   \n",
       "7                   Verizon  based on 14 salaries        ₹ 10.0L   \n",
       "8  Ganit Business Solutions  based on 13 salaries         ₹ 8.5L   \n",
       "9                  Ericsson  based on 42 salaries         ₹ 5.8L   \n",
       "\n",
       "  Average Salary Maximum Salary Experience Required  \n",
       "0        ₹ 28.7L        ₹ 35.0L           3 yrs exp  \n",
       "1        ₹ 19.5L        ₹ 25.0L         3-4 yrs exp  \n",
       "2        ₹ 15.8L        ₹ 20.0L           2 yrs exp  \n",
       "3        ₹ 15.0L        ₹ 22.0L         2-4 yrs exp  \n",
       "4        ₹ 15.0L        ₹ 21.3L         3-4 yrs exp  \n",
       "5        ₹ 13.5L        ₹ 20.5L         2-4 yrs exp  \n",
       "6        ₹ 13.5L        ₹ 18.5L         3-4 yrs exp  \n",
       "7        ₹ 12.7L        ₹ 21.0L           4 yrs exp  \n",
       "8        ₹ 12.4L        ₹ 15.0L           4 yrs exp  \n",
       "9        ₹ 11.9L        ₹ 21.5L         3-4 yrs exp  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9 = pd.DataFrame({'Company Name':s,'Number of salaries':b,'Minimum Salary':mi,'Average Salary':a,'Maximum Salary':mx,'Experience Required':e})\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cef8e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df9. to_csv('Ambition_box.csv') #converting the dataset to csv file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7688f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529066d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
